{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98b0c475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import joblib\n",
    "import gzip\n",
    "import kipoiseq\n",
    "from kipoiseq import Interval\n",
    "import pyfaidx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from deeplift import dinuc_shuffle\n",
    "sys.path.append('../../../enformer_fine_tuning/')\n",
    "import enformer_nomod as enformer\n",
    "import sonnet as snt\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import strings as tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59cf6ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Faidx(\"../../../reference_files/hg38.fa\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasta_file = \"../../../reference_files/hg38.fa\"\n",
    "pyfaidx.Faidx(fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5996a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastaStringExtractor:\n",
    "\n",
    "    def __init__(self, fasta_file):\n",
    "        self.fasta = pyfaidx.Fasta(fasta_file)\n",
    "        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n",
    "\n",
    "    def extract(self, interval: Interval, **kwargs) -> str:\n",
    "        # Truncate interval if it extends beyond the chromosome lengths.\n",
    "        chromosome_length = self._chromosome_sizes[interval.chrom]\n",
    "        trimmed_interval = Interval(interval.chrom,\n",
    "                                    max(interval.start, 0),\n",
    "                                    min(interval.end, chromosome_length),\n",
    "                                    )\n",
    "        # pyfaidx wants a 1-based interval\n",
    "        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n",
    "                                          trimmed_interval.start + 1,\n",
    "                                          trimmed_interval.stop).seq).upper()\n",
    "        # Fill truncated values with N's.\n",
    "        pad_upstream = 'N' * max(-interval.start, 0)\n",
    "        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n",
    "        return pad_upstream + sequence + pad_downstream\n",
    "\n",
    "    def close(self):\n",
    "        return self.fasta.close()\n",
    "\n",
    "def one_hot_encode(sequence):\n",
    "  return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c29954f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with strategy.scope():\n",
    "\n",
    "#SEQUENCE_LENGTH = 196608\n",
    "\n",
    "class Enformer:\n",
    "    def __init__(self):\n",
    "        \n",
    "        model = enformer.Enformer()\n",
    "        options = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
    "        checkpoint = tf.train.Checkpoint(module=model)#,options=options)\n",
    "        tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n",
    "        latest = tf.train.latest_checkpoint(\"gs://picard-testing-176520/BE_paper_pretraining/models/enformer_fine_tuning_LR15e-05_LR20.005_WD15e-05_WD20.05_WD20.05_enformer_fine_tuning/iteration_24\")\n",
    "        checkpoint.restore(latest,options).assert_existing_objects_matched()\n",
    "        self._model=model\n",
    "\n",
    "\n",
    "    def predict_on_batch(self, inputs):\n",
    "        return self._model.predict_on_batch(inputs)\n",
    "        #return {k: v.numpy() for k, v in predictions.items()}\n",
    "\n",
    "    @tf.function\n",
    "    def contribution_input_grad(self, input_sequence,\n",
    "                                target_mask, track_index):\n",
    "        input_sequence = input_sequence[tf.newaxis]\n",
    "\n",
    "        target_mask_mass = tf.reduce_sum(target_mask)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(input_sequence)\n",
    "            pred = self._model.predict_on_batch(input_sequence)#[:,:,track_index]\n",
    "\n",
    "            prediction = tf.reduce_sum(\n",
    "                  target_mask[tf.newaxis] * pred) / target_mask_mass\n",
    "\n",
    "        grad = tape.gradient(prediction, input_sequence)\n",
    "        input_grad = grad * input_sequence\n",
    "        input_grad = tf.squeeze(input_grad, axis=0)\n",
    "\n",
    "        return tf.reduce_sum(input_grad, axis=-1), grad\n",
    "\n",
    "# @title `variant_centered_sequences`\n",
    "#with strategy.scope():\n",
    "class FastaStringExtractor:\n",
    "\n",
    "    def __init__(self, fasta_file):\n",
    "        self.fasta = pyfaidx.Fasta(fasta_file)\n",
    "        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n",
    "\n",
    "    def extract(self, interval: Interval, **kwargs) -> str:\n",
    "        # Truncate interval if it extends beyond the chromosome lengths.\n",
    "        chromosome_length = self._chromosome_sizes[interval.chrom]\n",
    "        trimmed_interval = Interval(interval.chrom,\n",
    "                                    max(interval.start, 0),\n",
    "                                    min(interval.end, chromosome_length),\n",
    "                                    )\n",
    "        # pyfaidx wants a 1-based interval\n",
    "        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n",
    "                                          trimmed_interval.start + 1,\n",
    "                                          trimmed_interval.stop).seq).upper()\n",
    "        # Fill truncated values with N's.\n",
    "        pad_upstream = 'N' * max(-interval.start, 0)\n",
    "        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n",
    "        return pad_upstream + sequence + pad_downstream\n",
    "\n",
    "    def close(self):\n",
    "        return self.fasta.close()\n",
    "\n",
    "def one_hot_encode(sequence):\n",
    "    return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)\n",
    "\n",
    "\n",
    "def importance_scores(chrom, start, stop, target_index, mask_indices):\n",
    "\n",
    "    target_interval = kipoiseq.Interval(chrom, int(start), int(stop))\n",
    "    resized_interval = target_interval.resize(196608)\n",
    "    sequence_one_hot = one_hot_encode(fasta_extractor.extract(resized_interval))\n",
    "    #print(sequence_one_hot.shape)\n",
    "    print(sequence_one_hot[np.newaxis].shape)\n",
    "    predictions = model.predict_on_batch(sequence_one_hot[np.newaxis])[0]\n",
    "    print(predictions.shape)\n",
    "\n",
    "    target_mask = np.zeros_like(predictions)\n",
    "    for idx in mask_indices:\n",
    "        target_mask[idx, target_index] = 1\n",
    "    # This will take some time since tf.function needs to get compiled.\n",
    "    contribution_scores, grad = model.contribution_input_grad(sequence_one_hot.astype(np.float32), target_mask, target_index)\n",
    "    contribution_scores = contribution_scores.numpy()\n",
    "    pooled_contribution_scores = tf.nn.avg_pool1d(np.abs(contribution_scores)[np.newaxis,\n",
    "                                                                              :, np.newaxis],\n",
    "                                                  128, 128, 'VALID')[0, :, 0].numpy()\n",
    "\n",
    "    base_scores = (sequence_one_hot[:][:].T * [contribution_scores[:],\n",
    "                                                   contribution_scores[:],\n",
    "                                                   contribution_scores[:],\n",
    "                                                   contribution_scores[:]]).T\n",
    "\n",
    "    gradient = np.multiply(sequence_one_hot[:][:].T, (np.squeeze(grad).T))\n",
    "    ###### dinucleotide shuffled sequences\n",
    "    seq_shuffled = dinuc_shuffle.dinuc_shuffle(sequence_one_hot, 1)[0]\n",
    "\n",
    "    target_mask = np.zeros_like(predictions)\n",
    "    for idx in mask_indices:\n",
    "        target_mask[idx, target_index] = 1\n",
    "    # This will take some time since tf.function needs to get compiled.\n",
    "\n",
    "    contribution_scores_scram, grad_scram = model.contribution_input_grad(seq_shuffled, target_mask, target_index)\n",
    "    contribution_scores_scram = contribution_scores_scram.numpy()\n",
    "    pooled_contribution_scores_scram = tf.nn.avg_pool1d(np.abs(contribution_scores_scram)[np.newaxis,\n",
    "                                                                              :, np.newaxis],\n",
    "                                                  128, 128, 'VALID')[0, :, 0].numpy()\n",
    "\n",
    "    ## get base level matrix\n",
    "\n",
    "    base_scores_scram = (seq_shuffled[:][:].T * [contribution_scores_scram[:],\n",
    "                                        contribution_scores_scram[:],\n",
    "                                        contribution_scores_scram[:],\n",
    "                                        contribution_scores_scram[:]]).T\n",
    "\n",
    "    ## get base level matri\n",
    "    gradient_scram = np.multiply(seq_shuffled[:][:].T, (np.squeeze(grad_scram).T))\n",
    "\n",
    "\n",
    "\n",
    "    return resized_interval,contribution_scores,pooled_contribution_scores,base_scores,np.squeeze(grad), sequence_one_hot,base_scores_scram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d1df50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_out_bedgraph_pooled(pooled_contribution_scores, interval, filename_base):\n",
    "    start = interval.start\n",
    "    end =  interval.end\n",
    "    chrom = interval.chrom\n",
    "    name = '_'.join([str(chrom), str(start), str(end)])\n",
    "\n",
    "    out_file = open(filename_base + '.pooled.bedGraph', 'w')\n",
    "\n",
    "\n",
    "    for k, value in enumerate(pooled_contribution_scores):\n",
    "\n",
    "        start_interval = k * 128 + start\n",
    "        end_interval = (k+1) * 128 + start\n",
    "\n",
    "        line = [str(chrom),\n",
    "                str(start_interval), str(end_interval),\n",
    "                str(value)]\n",
    "\n",
    "        out_file.write('\\t'.join(line) + '\\n')\n",
    "    out_file.close()\n",
    "    \n",
    "def write_out_bedgraph_all(contribution_scores, interval, filename_base):\n",
    "    start = interval.start\n",
    "    end =  interval.end\n",
    "    chrom = interval.chrom\n",
    "    name = '_'.join([str(chrom), str(start), str(end)])\n",
    "\n",
    "    out_file = open(filename_base + '.all.bedGraph', 'w')\n",
    "\n",
    "\n",
    "    for k, value in enumerate(contribution_scores):\n",
    "\n",
    "        start_interval = start + k\n",
    "        end_interval = start + k + 1\n",
    "\n",
    "        line = [str(chrom),\n",
    "                str(start_interval), str(end_interval),\n",
    "                str(value)]\n",
    "\n",
    "        out_file.write('\\t'.join(line) + '\\n')\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a64705e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterator\n",
    "#with strategy.scope():\n",
    "model = Enformer()\n",
    "\n",
    "\n",
    "## center interval at the RE-4 boundaries, corresponding to 9,764,556 - 9,765,505\n",
    "chrom = \"chr12\"\n",
    "start = 9764556\n",
    "end = 9765505\n",
    "#SEQUENCE_LENGTH=196608*2 # add 6 bp to allow for the +/- 0-3 bp shift\n",
    "#target_length = 196608\n",
    "fasta_extractor = FastaStringExtractor(fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d796519a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 196608, 4)\n",
      "(896, 4)\n"
     ]
    }
   ],
   "source": [
    "mask_indices=[442,443,444,445,446,447,448,449,450,451,452,453,454]\n",
    "out = importance_scores(\"chr12\", 9764300, 9765900,3, mask_indices) # Jurkat resting corresponds to index 3\n",
    "resized_int, scores, pooled, base_scores,grad, seq_one_hot,base_scores_shuff = out\n",
    "write_out_bedgraph_pooled(pooled,\n",
    "                          resized_int,\n",
    "                          'enformer_ft_pooledscores_Jurkat_resting.bedGraph')\n",
    "write_out_bedgraph_all(np.abs(scores),\n",
    "                          resized_int,\n",
    "                          'enformer_ft_scores_Jurkat_resting.bedGraph')\n",
    "\n",
    "np.save(\"Jurkat_resting.basescores.npy\", np.array(base_scores))#, fmt='%10.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42224da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Jurkat_resting.basescores.npy\", np.array(base_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c62edfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 196608, 4)\n",
      "(896, 4)\n"
     ]
    }
   ],
   "source": [
    "out_2 = importance_scores(\"chr12\", 9764300, 9765900,2, mask_indices)\n",
    "resized_int_2, scores_2, pooled_2, base_scores_2,grad_2, seq_one_hot_2,base_scores_shuff_2 = out_2\n",
    "write_out_bedgraph_pooled(pooled_2,\n",
    "                          resized_int,\n",
    "                          'enformer_ft_pooledscores_Jurkat_activated.bedGraph')\n",
    "write_out_bedgraph_all(np.abs(scores_2),\n",
    "                          resized_int,\n",
    "                          'enformer_ft_scores_Jurkat_activated.bedGraph')\n",
    "\n",
    "np.save(\"Jurkat_activated.basescores.npy\", np.array(base_scores_2))#, fmt='%10.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "892082d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_3 = importance_scores(\"chr12\", 9764300, 9765900,1, mask_indices)\n",
    "resized_int_3, scores_3, pooled_3, base_scores_3,grad_3, seq_one_hot_3,base_scores_shuff_3 = out_3\n",
    "\n",
    "write_out_bedgraph_pooled(pooled_3,\n",
    "                          resized_int,\n",
    "                          'enformer_ft_pooledscores_CD4_resting.bedGraph')\n",
    "write_out_bedgraph_all(scores_3,\n",
    "                          resized_int,\n",
    "                          'enformer_ft_scores_CD4_resting.bedGraph')\n",
    "\n",
    "np.save(\"CD4_resting.basescores.npy\", np.array(base_scores_3))#, fmt='%10.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73608392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 196608, 4)\n",
      "(896, 4)\n"
     ]
    }
   ],
   "source": [
    "mask_indices=[442,443,444,445,446,447,448,449,450,451,452,453,454]\n",
    "out_4 = importance_scores(\"chr12\", 9764300, 9765900,0, mask_indices)\n",
    "resized_int_4, scores_4, pooled_4, base_scores_4,grad_4, seq_one_hot_4,base_scores_shuff_4 = out_4\n",
    "#viz_sequence.plot_weights(base_scores_4[98100:98200,:], subticks_frequency=20)\n",
    "\n",
    "write_out_bedgraph_pooled(pooled_4,\n",
    "                          resized_int,\n",
    "                          'enformer_ft_pooledscores_CD4_activated.bedGraph')\n",
    "write_out_bedgraph_all(scores_4,\n",
    "                          resized_int,\n",
    "                          'enformer_ft_scores_CD4_activated.bedGraph')\n",
    "np.save(\"CD4_activated.basescores.npy\", np.array(base_scores_4))#, fmt='%10.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636afe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "r-cpu.4-0.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-0:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
